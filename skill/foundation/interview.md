# 经历面试问题总结

## 数据库方面

1. 数据库设计的三大范式

    第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式, 例如地址可以拆分为省份，城市，详细地址多个部分

    第二范式： 首先是第一范式，另外包含两部分内容，一是表必须有主键，二是没有包含在主键中的列必须完全依赖与主键，而不能只依赖主键的一部分
    例如：订单明细表：OrderDetail（OrderId, ProductId,单价，折扣，数量，产品名称），对于一个订单它可能有多个商品，那么单单一个OrderId不足以做主键，因此会使用OrderId和ProductId做为联合主键。 折扣，数量是严格与联合主键关联，但是单价，产品名称却只和ProductId相关，因此不满足2NF，所以需要将单价和产品名称拆到一张单独的表中，防止在订单详情表中多余产品信息的冗余（因为如果每个订单都包含订单单价和订单名称，那么多个订单会重复出现该数据，造成冗余）。但是也有意外情况，即我需要单价和产品名称来做历史记录，防止产品信息更改后造成历史数据的丢失

    第三范式： 首先是2NF，其次非主键列必须直接依赖于主键列，而不能存在传递依赖，即不能存在A列依赖于B列，B列依赖于主键列
    例如订单表：Order（OrderID，createTime, customerId, customerName, customerAddr),其中OderID是主键，其他列都于主键相关，但是CustomerName，customerAddr于customerId直接相关，而并非于orderId直接相关，因此不满足3NF，需要将数据库表进行拆分

    其他： BCNF： 
    第四范式：要求把同一表内的多对多关系删除
    五范式：从最终结构重新建立原始结构？？


2. 数据库设计过程中有那些注意事项或者优化原则

- 库设计：
     数据库名称要明确，可以加前缀或后缀，要有业务含义
     不同类型的数据应分开管理，如财务数据，业务数据
     尽可能少用存储过程，不要让数据库处理过多逻辑，将业务放到应用中

- 表设计：
   - 数据尽量不要进行物理删除，应添加一个标志位，以防用户后悔时无法恢复
   - 数据添加是否有效的标识位
   - 字段排序 将数据库字段按照一定的规则进行排序，方便查找
   - 是否需要记录时间，创建时间和更新时间等
   - 数据库字段尽可能添加默认值
   - 如果两个表存在多对多的关系，尽可能在添加一张关联表，将其转化为一对多的关系
   - 表的垂直拆分，经常查询的字段放置到一个表中，把text， blob类型的数据拆分到另一个表中
   - 禁止使用select (*)这样的查询

   索引：
    索引需要根据where groupby等语句后的条件按照一定的顺序进行排列
    索引的个数需要控制在3个以内
    对于字符串索引，需要添加索引的长度控制，防止索引太大，占据太多空间

索引的弊端: 一是创建索引要耗费时间，二是索引要占有大量磁盘空间，三是增加了维护代价（在修改带索引的数据列时索引会减缓修改速度）

3. Mysql数据库有哪几种引擎，各自的特性是什么

+-------------+------+----------------------+-------------------------------+------------------------+
| 存储引擎    | 事务 | 锁粒度               | 主要应用                      | 忌用                   |
+=============+======+======================+===============================+========================+
| MyISAM      | No   | 支持并发插入的表级锁 | SELECT，INSERT                | 读写操作频繁           |
+-------------+------+----------------------+-------------------------------+------------------------+
| MRG-MyISAM  | No   | 支持并发插入的表级锁 | 分段归档，数据仓库            | 全局查找过多的场景     |
+-------------+------+----------------------+-------------------------------+------------------------+
| Innodb      | Yes  | 支持MVCC级别的行级锁 | 事务处理                      | 无                     |
+-------------+------+----------------------+-------------------------------+------------------------+
| Archine     | No   | 行级锁               | 日记记录，只支持insert select | 需要随机读取 更新 删除 |
+-------------+------+----------------------+-------------------------------+------------------------+
| NDB Cluster | Yes  | 行级锁               | 高可用                        | 大部分应用             |
+-------------+------+----------------------+-------------------------------+------------------------+

Innodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这篇文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表

MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。不过和Innodb不同，MyIASM中存储了表的行数，于是SELECT COUNT(*) FROM TABLE时只需要直接读取已经保存好的值而不需要进行全表扫描。如果表的读操作远远多于写操作且不需要数据库事务的支持，那么MyIASM也是很好的选择

大尺寸的数据集趋向于选择InnoDB引擎，因为它支持事务处理和故障恢复。数据库的大小决定了故障恢复的时间长短，InnoDB可以利用事务日志进行数据恢复，这会比较快。主键查询在InnoDB引擎下也会相当快，不过需要注意的是如果主键太长也会导致性能问题，关于这个问题我会在下文中讲到。大批的INSERT语句(在每个INSERT语句中写入多行，批量插入)在MyISAM下会快一些，但是UPDATE语句在InnoDB下则会更快一些，尤其是在并发量大的时候

## ZK+Kafka
1. 为什么kafka需要使用zkeeper， 能够替代zk

    kafka需要一个地方存储元数据以及交换集群信息，使用zookeeper的watch机制来发现meta的变更以及做出相应的动作
    kafka broker启动后会在zk建立一个临时节点(当broker挂掉后，删除该临时节点),随后向broker注册自己持有的topic和partitions
    consumer and consmergroup 一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上
    
状态同步：
    consmer 保存消费的offset到zookeeper
    partition leader 注册在zk中，Producer作为client，通过注册Watch用来监听partition leader的变更事件
    zk支持kafka的partition leader／follower的协同和选举，保证partition中只要有leader／follower就不会停止服务


总结：
    Producer通过zk来发现borker列表，并通过于topic下的每个partition leader建立连接关系并发送消息
    Borker用zk来注册borker信息，以及检测partion leader的存活性
    Consumer使用zk来组成consumer信息，包括consumer消费的partition信息等，同时也可以用来发现borker列表，并同partitionleader建立连接来消费信息


换言之需要知道现在那些生产者（对于消费者而言，kafka就是生产者）是可用的。 如果没了zk消费者如何知道呢？如果每次消费者在消费之前都去尝试连接生产者测试下是否连接成功，效率呢？ 所以kafka需要zk，在kafka的设计中就依赖了zk了

2. ZK的使用场景有哪些
    
    常见的使用场景包括：配置管理， 统一命名服务，提供分布式同步，集群管理

3. ZK的特性，包括Watch之类的特性

3. kafka与其他消息队列的对比，为什么告警使用kafka而不使用其他队列


## Redis
1. Redis的两种方式，各自有什么优缺点，以及注意事项
    
    RDB:可以在指定时间内生成数据集的时间点快照(point-in-time snapshot)
    AOF: 记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集, AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。
    Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整

    RDB优点：
    - RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本
    - RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中
    - RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作
    - RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。
    缺点：
    - 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据
    - 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失

    AOF优点：
    - 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）
    - AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题
    - Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作
    - AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。
    AOF缺点：
    - 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积
    - 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）
    - AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的

    RDB : save 60 1000  60 秒内有至少有 1000 个键被改动,就自动保存一次数据集

    当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作：
    ```
    Redis 调用 fork() ，同时拥有父进程和子进程。
    子进程将数据集写入到一个临时 RDB 文件中。
    当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。
    这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。
    ```

    快照功能并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。
    尽管对于某些程序来说， 数据的耐久性并不是最重要的考虑因素， 但是对于那些追求完全耐久能力（full durability）的程序来说， 快照功能就不太适用了
    通过设置appendonly yes， 保证每个命令都会被刷新到aof

    AOF 有多耐久？
    你可以配置 Redis 多久才将数据 fsync 到磁盘一次。

    有三个选项：
        - 每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。
        - 每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。
        - 从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。
    推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性

    AOF运作方式：
    AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制。

    以下是 AOF 重写的执行步骤：
    - Redis 执行 fork() ，现在同时拥有父进程和子进程。
    - 子进程开始将新 AOF 文件的内容写入到临时文件。
    - 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。
    - 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。
    - 搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。

备份建议：
- 创建一个定期任务（cron job）， 每小时将一个 RDB 文件备份到一个文件夹， 并且每天将一个 RDB 文件备份到另一个文件夹。
- 确保快照的备份都带有相应的日期和时间信息， 每次执行定期任务脚本时， 使用 find 命令来删除过期的快照： 比如说， 你可以保留最近 48 小时内的每小时快照， 还可以保留最近一两个月的每日快照。
- 至少每天一次， 将 RDB 备份到你的数据中心之外， 或者至少是备份到你运行 Redis 服务器的物理机器之外。

2. Redis处理用来做缓存外，还可以用来做什么(它的使用场景)

    - Redis缓存-热数据
    - 计数器 INCRBY
    - 队列 不仅可以把并发请求变成串行，并且还可以做队列或者栈使用
    - 位操作（大数据处理）setbit getbit bitcount
    - 分布式锁与单线程机制 
        验证前端的重复请求（可以自由扩展类似情况），可以通过redis进行过滤：每次请求将request Ip、参数、接口等hash作为key存储redis（幂等性请求），设置多长时间有效期，然后下次请求过来的时候先在redis中检索有没有这个key，进而验证是不是一定时间内过来的重复提交
        秒杀系统，基于redis是单线程特征，防止出现数据库“爆破”
        全局增量ID生成，类似“秒杀”
    - Redis订阅/发布
    

3. Redis的数据key返回类型有那些
Type 命令用于返回 key 所储存的值的类型
- String 
- Hash
- List
- Set
- Sorted set
- pub/sub
- Transactions

4. Redis的常见问题

5. Redis 淘汰策略
- volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
- volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
- allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
- no-enviction（驱逐）：禁止驱逐数据

## Java 基础

1. JVM内存模型，以及各个模块的作用

2. 常用集合类以及AQS的作用

3. synchronized 锁的类型和锁的作用范围

4. synchronized 与 Lock的区别

5. 常用的线程安全类以及使用场景

6. ThreadLocal的使用场景

7. IO, NIO, AIO的区别
