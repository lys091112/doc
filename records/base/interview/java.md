# Java

## JVM 优化
一些可能导致内存溢出的原因
    - 堆内存设置太小
    - 永久代设置太小(java8已不存在这个问题,因为metaspace已经替代了perm)
    - 代码中创建了很多大对象 , 且一直因为被引用不能被回收
    - 长生命周期对象持有短生命周期对象的引用
    - 静态集合类引起的内存泄漏 , 例如HashMap和Vector等  因为他们是静态的, 他们的生命周期与应用一致 , 所以他们引用的对象不会被释放 , 所以需要特别注意自己是否有静态集合存了许多对象的情况
    - 单例模式 单例对象初始化后再JVM整个生命周期中存在 , 如果单例对象持有对外部对象的引用那么整个对象不会被JVM回收
    - 全局集合
    - 类加载器 


1. 代码中创建了很多大对象 , 且一直因为被引用不能被回收

```
    0) 使用jstat查看gc情况
    1) 使用jmap -heap pid查看堆使用情况
    2) 使用jmap -histo:live pid 查看实例数和实例所占内存大小
    3) 第三步, 统计所有实例所占内存大小 jmap -histo:live 17863|awk ‘{if(NR>3)a+=\$3}END{print a}’ 

```

2.  java进程高负载问题排查

```
    - 执行top -c命令，找到cpu最高的进程的id
    - 使用top -H -p #{pid} 命令，查看当前java进程中的各线程的资源使用情况；
    - 找出负载高的线程，记录pid（26507）；
    - 使用printf "%x\n" 26507命令，将线程的pid（26507）转换为16进制字符串（678b）；
    - 在jstack -l pid 导出的java进程的堆栈信息中，查找字符串678b，即可定位负载高的线程的堆栈信息
```


## 2. JVM 基础

### 2.1. java new一个对象的执行过程

```
    1. 虚拟机先执行class文件
    2. 执行class类的static静态代码
    3. 开堆内存开辟空间，分配地址
    4. 在堆内存中建立对象的特有属性（成员变量），并进行默认初始化
    5. 对属性进行显示初始化
    6. 对对象a进行构造初始化
    7. 将内存地址传递给a
```

### 2.2. 类的生命周期
类加载一般分为加载，连接，初始化三个阶段·
```
    1. 加载
        - 通过一个类的全限定名来获取定义此类的二进制字节流。
        - 将这个字节流代表的静态存储结构转化为为方法区的运行时数据结构。
        - 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类各种数据的访问入口。
    2. 连接
        - 验证
            1. 文件格式验证。 包括是否以0xCAFFBABE开头，版本号是否可以当前虚拟机执行，常量池常量类型是否支持等等。。。
            2. 元数据验证。 针对语义分析，是否有父类，父类是否继承了不允许继承的类是否抽象，子类是否是实现接口中的方法等等。。
            3. 字节码验证。 确认数据流和控制流分析远程是合法的，并对类的方法进行校验，保证类方法在运行期间不会做出危害虚拟机安全的事件
            4. 符号引用。  将符号引用转化为直接引用，对引用做匹配性校验。如方法的访问性，是否可以通过全量名找到对应的类
        - 准备
            1. 正式为类变量分配内存并设置类变量的初始值
            2. 这个分配内存的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量会在对象实例化时随着对象一起配置到java堆中。例如： 

        - 解析 将常量池内的符号引用替换为直接引用的过程
            1. 类和接口解析
            2. 字段解析
            3. 类方法解析
            4. 接口方法解析


    3. 初始化
        类的初始化:有且只有的5种对类初始化的情况
        1. 遇到 new, putstatic, getstatic, invokestatic 这四个指令时，需要先触发类的初始化。 关键字的常用场景： 使用new初始化实例对象，获取静态
        变量，为静态变量赋值时（被final修饰的除外，已经被放到常量池中），  掉哟过一个类静态方法时
        2. 使用 java.lang.reflect 对类进行反射调用的时候，如果类没有初始化，则触发初始化
        3. 当初始化一个类的时候，如果父类没有初始化，会先初始化父类
        4. 虚拟机启动时，需要用户指定一个主类（包含main方法的类）， 虚拟机会先初始化这个主类
        5. 使用ＪＤＫ1.7动态语言支持时， 如果一个java.lang.invoke.MethodHandle 实例最后的解析结果是REF_static, REF_putstatic, REF_invokestatic
        的方法句柄，并且这个方法没有被初始化，则需要先进行初始化


```
### 2.3. JVM内存模型，以及各个模块的作用

    - 线程私有域:
        1.  Program Counter Register(程序计数器), 作用是当前线程所执行字节码的行号指示器(类似于传统cpu的pc), 字节码解释器就是通过改变PC值来选取下一条需要执行的字节码指令,分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖PC完成
        2. Java Stack(虚拟机栈) 虚拟机栈描述的是Java方法执行的内存模型: 每个方法被执行时会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息. 每个方法被调用至返回的过程, 就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程
        3. Native Method Stack(本地方法栈)：基本同虚拟机栈，本地方法栈则为Native方法服务
    - 线程共享区域
        1. Method Area(方法区),即我们常说的永久代，用于存储被JVM加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 运行时常量池，方法区的一部分. Class文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项常量池(Constant Pool Table)用于存放编译期生成的各种字面量和符号引用
        2. Heap(Java堆) 几乎所有对象实例和数组都要在堆上分配(栈上分配、标量替换除外), 因此是VM管理的最大一块内存, 也是垃圾收集器的主要活动区域. 由于现代VM采用分代收集算法, 因此Java堆从GC的角度还可以细分为: 新生代(Eden区、From Survivor区和To Survivor区)和老年代; 而从内存分配的角度来看, 线程共享的Java堆还还可以划分出多个线程私有的分配缓冲区(TLAB). 而进一步划分的目的是为了更好地回收内存和更快地分配内存
    - 直接内存
        直接内存并不是JVM运行时数据区的一部分, 但也会被频繁的使用: 在JDK 1.4引入的NIO提供了基于Channel与Buffer的IO方式, 它可以使用Native函数库直接分配堆外内存, 然后使用DirectByteBuffer对象作为这块内存的引用进行操作(详见: Java I/O 扩展), 这样就避免了在Java堆和Native堆中来回复制数据, 因此在一些场景中可以显著提高性能.

    java7 and java8:
    持久代已经被彻底删除了，取代它的是另一个内存区域也被称为元空间
        - 它是本地堆内存中的一部分
        - 它可以通过-XX:MetaspaceSize和-XX:MaxMetaspaceSize来进行调整
        - 当到达XX:MetaspaceSize所指定的阈值后会开始进行清理该区域
        - 如果本地空间的内存用尽了会收到java.lang.OutOfMemoryError: Metadata space的错误信息。
        - 和持久代相关的JVM参数-XX:PermSize及-XX:MaxPermSize将会被忽略掉，并且在启动的时候给出警告信息。
        - 充分利用了Java语言规范中的好处：类及相关的元数据的生命周期与类加载器的一致
    元空间 —— 调优
        - 使用-XX:MaxMetaspaceSize参数可以设置元空间的最大值，默认是没有上限的，也就是说你的系统内存上限是多少它就是多少。
        - 使用-XX:MetaspaceSize选项指定的是元空间的初始大小，如果没有指定的话，元空间会根据应用程序运行时的需要动态地调整大小。
        -  一旦类元数据的使用量达到了“MaxMetaspaceSize”指定的值，对于无用的类和类加载器，垃圾收集此时会触发。为了控制这种垃圾收集的频率和延迟，合适的监控和调整Metaspace非常有必要。过于频繁的Metaspace垃圾收集是类和类加载器发生内存泄露的征兆，同时也说明你的应用程序内存大小不合适，需要调整。

#### 2.3.1. 内存操作规则
    主内存和工作内存：
        java内存模型中规定了所有变量都存贮到主内存（如虚拟机物理内存中的一部分）中。每一个线程都有一个自己的工作内存(如cpu中的高速缓存)。线程中的工作内存保存了该线程使用到的变量的主内存的副本拷贝。线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行。不同线程之间无法直接访问对方工作内存中变量。线程间变量的值传递均需要通过主内存来完成

   java内存模型定义了8种操作来完成。这8种操作每一种都是原子操作
        - lock(锁定)：作用于主内存，它把一个变量标记为一条线程独占状态；
        - unlock(解锁)：作用于主内存，它将一个处于锁定状态的变量释放出来，释放后的变量才能够被其他线程锁定；
        - read(读取)：作用于主内存，它把变量值从主内存传送到线程的工作内存中，以便随后的load动作使用；
        - load(载入)：作用于工作内存，它把read操作的值放入工作内存中的变量副本中；
        - use(使用)：作用于工作内存，它把工作内存中的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时候，将会执行这个动作；
        - assign(赋值)：作用于工作内存，它把从执行引擎获取的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时候，执行该操作；
        - store(存储)：作用于工作内存，它把工作内存中的一个变量传送给主内存中，以备随后的write操作使用；
        - write(写入)：作用于主内存，它把store传送值放到主内存中的变量中。

    Java内存模型还规定了执行上述8种基本操作时必须满足如下规则:
        - 不允许read和load、store和write操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。
        - 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
        - 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。
        - 一个新的变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。
        - 一个变量在同一个时刻只允许一条线程对其执行lock操作，但lock操作可以被同一个条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
        - 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。
        - 如果一个变量实现没有被lock操作锁定，则不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
        对一个变量执行unlock操作之前，必须先把此变量同步回主内存（执行store和write操作）


### 2.4. 类卸载条件
```
    - 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
    - 加载该类的ClassLoader已经被回收。
    - 该类对应的java.lang.Class对象没有任何地方被引用，没有在任何地方通过反射访问该类的方法。
```

### 2.5. 可作为GCROOT的对象有：
```
    - 虚拟机栈中引用的对象
    - 方法区中静态属性引用的对象
    - 方法区中常量引用的对象
    - 本地方法栈中JNI引用的对象
```

### 2.6. 四种引用对象
```
    强引用： 只要引用还存在，那么就不会被垃圾收集器回收
    软引用： 有用但非必须的对象 在系统简要发生内存溢出异常之前，会把这些对象列入回收范围进行二次回收，如果仍不够，才会抛出内存溢出。 java类为：SoftReference
    弱引用： 被虚引用关联的对象只能生存到下一次垃圾回收之前。垃圾回收器工作后，无论内存是否足够，都会将该类对象进行收集。java类： WeakReference
    虚引用： 存在的唯一目的是在进行垃圾回收之前，收到一个系统通知，被虚引用关联的对象和其生存时间完全没有关系。java类： PhantomReference  例如：DirectByteBuffer中的Cleaner就是一个虚引用，在进行垃圾回收时会收到通知进而调用run方法对堆外内存进行回收
```

### 2.7 Collection

1. ArrayLIst 扩容过程 

```
    - ArrayList动态扩容的全过程。如果通过无参构造的话，初始数组容量为0，当真正对数组进行添加时，才真正分配容量。每次按照1.5倍（位运算）的比率通过copeOf的方式扩容。 在JKD1.6中实现是，如果通过无参构造的话，初始数组容量为10，每次通过copeOf的方式扩容后容量为原来的1.5倍，以上就是动态扩容的原理。
```

2. hashMap 扩容
```
    初始容量定义：默认为1 << 4（16）。最大容量为1<< 30。
    扩容加载因子为(0.75)，第一个临界点在当HashMap中元素的数量等于table数组长度*加载因子（16*0.75=12）， 如果超出则按oldThr << 1（原长度*2）扩容
```

3. HashSet 扩容
```
    - 初始容量定义：16。因为构造一个HashSet，其实相当于新建一个HashMap，然后取HashMap的Key。 扩容机制和HashMap一样
```
4. hashtable 扩容
```
    - 初始容量定义：capacity (11)
    - 扩容加载因子(0.75)，当超出默认长度（int）（11*0.75）=8时，扩容为old*2+1。 int newCapacity = (oldCapacity << 1) + 1
```


### 2.8. Java并发

1. java 并发中常见的几种锁机制

锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级）。JDK 1.6中默认是开启偏向锁和轻量级锁的，我们也可以通过-XX:-UseBiasedLocking来禁用偏向锁

“轻量级” 是相对于使用操作系统互斥量来实现的传统锁而言的。但是轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用产生的性能消耗。轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀为重量级锁

   - 偏向锁 核心的思想是，如果程序没有竞争，则取消之前已经取得锁的线程同步操作。也就是说，若某一锁被线程获取后，便进入偏向模式，当线程再次请求这个锁时，就无需再进行相关的同步操作了，从而节约了操作时间，如果在此之间有其他的线程进行了锁请求，则持有偏向锁的线程会被挂起，JVM尝试消除它身上的偏向锁，将锁恢复到标准轻量级锁。在JVM中使用-XX:+UseBiasedLocking 禁用偏向锁. 在线程竞争比较严重的程序中，可以禁用偏向锁，减少锁升级性能消耗


   - 如果偏向锁失败，轻量级锁（Lightweight Locking）利用了CPU原语Compare-And-Swap(CAS，汇编指令CMPXCHG)，尝试在进入互斥前，进行补救，减少多线程进入互斥的几率。 如果偏向锁失败，那么系统会进行轻量级锁的操作，使用CAS操作来尝试加锁。如果轻量级锁失败，才调用系统级别的重量级锁（syncrhoized）来加锁


   - 重量级锁 Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”
       

   - 自旋锁 当线程申请锁时，锁被占用，则让当前线程执行一个忙循环（自旋），看看持有锁的线程是否会很快释放锁。如果自旋后还没获得锁，才进入同步阻塞状态

2. synchronized 锁的类型和锁的作用范围
    synchronized 是针对于对象级别的锁，如果同于同一个类有多个实例，那么实例与实例之间是不会受synchronized影响
    synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量

3. synchronized 与 Lock的区别

    - 锁的种类
        1. 可重入锁:synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举比如说，当一个线程执行到method1 的synchronized方法时，而在method1中会调用另外一个synchronized方法method2，此时该线程不必重新去申请锁，而是可以直接执行方法method2
        2. 读写锁;读写锁将对一个资源的访问分成了2个锁，如文件，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突
        3. 可中断锁:在Java中，synchronized就不是可中断锁，而Lock是可中断锁。 如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁
        4.  公平锁:公平锁即尽量以请求锁的顺序来获取锁。同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁公平锁即尽量以请求锁的顺序来获取锁
    - syncchronized 的用法
        1. 锁定一段代码块
        2. 锁定一个方法
        3. 锁定一个类实例 例如：synchronized(this)
        4. 锁定一个类 例：synchronized(Test.class)
    - lokc 常见方法
        1. void lockInterruptibly() throws InterruptedException;
        2. boolean tryLock(); 
        3. boolean tryLock(long time, TimeUnit unit) throws InterruptedException; 
        4. void unlock(); 
        5. Condition newCondition();
    - 两种锁对比：
        1. lock是一个接口，而synchronized 是java内置关键字
        2. synchronized 发生异常时会自动释放锁，而lock需要手动释放，一般会使用try{}finallly{}结构并在finally中释放
        3. lock 可以使等待锁线程响应中断，而synchronized不能响应中断，会一直等下去
        4. lock可以知道锁的状态，而synchronized无法知道



**锁的基本升级过程:**
```
线程1当前拥有偏向锁对象,线程2是需要竞争到偏向锁
    - 线程2来竞争锁对象;
    - 判断当前对象头是否是偏向锁;
    - 判断拥有偏向锁的线程1是否还存在;
    - 线程1不存在,直接设置偏向锁标识为0(线程1执行完毕后,不会主动去释放偏向锁);
    - 使用cas替换偏向锁线程ID为线程2,锁不升级，仍为偏向锁;
    - 线程1仍然存在,暂停线程1；
    - 设置锁标志位为00(变为轻量级锁),偏向锁为0;
    - 从线程1的空闲monitor record中读取一条,放至线程1的当前monitor record中;
    - 更新mark word，将mark word指向线程1中monitor record的指针;
    - 继续执行线程1的代码;
    - 锁升级为轻量级锁;   
    - 线程2自旋来获取锁对象;

如果判断一个线程是否存在：(分析thread.cpp)
    - 线程执行start时，会将自己写入一个thread_list中,这是一个linked结构，有pre和next节点;
    - 线程执行完后,会将自己从thread list中清理掉(源码位置: Threads::remove(this)); 因此只需判断thread list中是否存在线程1即可
```

**优化策略:**
```
    1. 减少锁的持有时间。 例如缩小锁的范围
    2. 减小锁的粒度。 例如concurrenthashmap 将数据分为几个segment，分别锁
    3. 锁分离。 读写锁的性质，读锁之间不会相互互斥，提高并发性
    4. 锁粗化。 如果不连续的代码段频繁使用锁，可以将其合并为一个，减少锁切换消耗
    5. 锁消除。 这是编译器自带的优化措施    
```

2. 线程池的使用
   - **ThreadPoolExecutor参数信息**

        | 参数名 | 作用|
        |-------|-------|
        | corePoolSize | 核心线程池大小|
        | maximumPoolSize| 最大线程池大小 |
        | keepAliveTime| 线程池中超过corePoolSize数目的空闲线程最大存活时间 |
        | timeUnit | keepAliveTime时间单位 |
        | workQueue| 阻塞任务队列|
        | threadFactory | 新建线程工程，常用来制定线程名称等 |
        | RejectedExecutionHandler | 当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理 |

    - **corePoolSize, workQueue, maximumPoolSize 的关系**

        ```
        有新的任务时：
            当线程数小于核心线程数时，创建新线程,无需进入队列等待
            当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列，此时不会创建新线程。
            当线程数大于等于核心线程数，且任务队列已满
            若线程数小于最大线程数，创建新线程
            若线程数等于最大线程数，抛出异常，拒绝任务
        ```

3. 创建线程的3种方式
```
    1. new Thread 类
    2. 继承Runnable接口
    3. 继承Callable接口，可以通过FutureTask来获取执行结果
```

## java IO

1. 对外内存
```
常使用的申请方式： ByteBuffer.allocteDirect(XXXX)

```
2. 堆外内存的使用
```
堆外内存申请的两种方式：
1. ByteBuffer.allocateDirect(xxx)
这种申请会在进行垃圾回收时被jvm回收

2. unsafe.allocateMemory(xx)
这种申请方式需要手动进行垃圾回收
```


### 2.9 java 其他

1. ThreadLocal 内存泄漏问题
```
ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用来引用它，那么系统 GC 的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value永远无法回收，造成内存泄漏。

ThreadLocalMap是被设置到thread中，是thread的一个成员变量，key为threadlocal， value为引用的值

其实，ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施：在ThreadLocal的get(),set(),remove()的时候都会清除线程ThreadLocalMap里所有key为null的value。

但是这些被动的预防措施并不能保证不会内存泄漏：
    使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏
    分配使用了ThreadLocal又不再调用get(),set(),remove()方法，那么就会导致内存泄漏。


原因主要为： 由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用

因此在使用threadLocal时需要注意：每次使用完ThreadLocal，都调用它的remove()方法或者set(null)，清除数据
像使用lock一样每次都手动进行unlock，防止内存泄漏

```

#### 2.9.1 ThreadLocal 常用使用方法
 - 日期的初始化，因为日期格式化函数非线程安全，保证每个线程使用的日期格式化函数都是各自唯一的
 - 保存数据库连接Connection， 保证每个线程都使用线程唯一的connection处理连接


7. IO, NIO, AIO的区别
    - IO(同步阻塞BIO)
        同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
    - NIO(同步非阻塞)
        同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。用户进程也需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问
    - AIO(异步非阻塞)
        服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理

    总结：
        第一点，NIO少了1次从内核空间到用户空间的拷贝
        第二点，NIO以块处理数据，IO以流处理数据
        第三点，非阻塞，NIO1个线程可以管理多个输入输出通道

8. 直接内存和非直接内存的区别
    - 性能比较：
         直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显
        直接内存IO读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显
    - 从数据流的角度，来看
        非直接内存作用链:
        本地IO –>直接内存–>非直接内存–>直接内存–>本地IO
        直接内存作用链:
        本地IO–>直接内存–>本地IO

    直接内存的使用场景：1.  有很大的数据需要存储，它的生命周期很长 2. 适合频繁的IO操作，例如网络并发场景
    正常情况下，JVM创建缓冲区的时候做了如下几步：
    1.JVM确保Heap区域内的空间足够，如果不够则使用触发GC在内的方法获得空间;
    2.获得空间之后会找一组堆内的连续地址分配数组, 这里需要注意的是，在物理内存上，这些字节是不一定连续的;
    3.对于不涉及到IO的操作，这样的处理没有任何问题，但是当进行IO操作的时候就会出现一点性能问题.

    所有的IO操作都需要操作系统进入内核态才行，而JVM进程属于用户态进程, 当JVM需要把一个缓冲区写到某个Channel或Socket的时候，需要切换到内核态.

    而内核态由于并不知道JVM里面这个缓冲区存储在物理内存的什么地址，并且这些物理地址并不一定是连续的(或者说不一定是IO操作需要的块结构)，所以在切换之前JVM需要把缓冲区复制到物理内存一块连续的内存上, 然后由内核去读取这块物理内存，整合成连续的、分块的内存.

    也就是说如果我们这个时候用的是非直接缓存的话，我们还要进行“复制”这么一个操作，而当我们申请了一个直接缓存的话，因为他本是就是一大块连续地址，我们就可以直接在它上面进行IO操作，省去了“复制”这个步骤

9. 范型以及范型的使用
   class Fruit{} 
   class Apple extend Fruit{}
   class Orange extend Fruit{}
    <? extends Fruit> 上界通配符，表示元素是任何从Fruit类型继承的列表，但该元素可能是Apple，也可能是Orange， 因此无法确定可以添加的具体类型，也就是该范型变量无法添加元素，只能从其中获取
    <? super Fruit> 下界通配符，表明元素是具有任何Fruit的超类的列表。列表至少是一个Fruilt型，因此可以添加Fruit以及Fruilt的子类。 但是取元素时需要进行强转。

10. 数据库分库分表

11. java JNDI RMI JMS
    - JNDI java（Java Naming and Directory Interface）：java命名和目录接口,它是为JAVA应用程序提供命名和目录访问服务的API
    - RMI:远程方法调用(Remote Method Invocation)。能够让在某个java虚拟机上的对象像调用本地对象一样调用另一个java 虚拟机中的对象上的方法
    ```
    clent.java
        Hello h = (Hello)Naming.lookup("rmi://192.168.58.164:12312/Hello");
        System.out.println(h.sayHello("zx"));
        1. 从代码中也可以看到，代码依赖于ip与端口
        2. RMI依赖于Java远程消息交换协议JRMP（Java Remote Messaging Protocol），该协议为java定制，要求服务端与客户端都为java编写

    ```
    - JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持
    ```
        1、Point-to-Point(P2P)
　　　　2、Publish/Subscribe(Pub/Sub)

    ```

12. thread 

    - wait() and sleep()方法的区别： wait() 会释放锁，而sleep()不会释放锁
    - wait() and notify() 是Object的方法，而不是Thread的方法
    - 状态说明：
        1. 新建(new)：新创建了一个线程对象。
        2. 可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。
        3. 运行(running)：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。
        4. 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：
            (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
            (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
            (三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。
        5. 死亡(dead)：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

13. volatile 特性
    - 禁止指令重排
        1、当第二个操作为volatile写操做时,不管第一个操作是什么(普通读写或者volatile读写),都不能进行重排序。这个规则确保volatile写之前的所有操作都不会被重排序到volatile之后;
        2、当第一个操作为volatile读操作时,不管第二个操作是什么,都不能进行重排序。这个规则确保volatile读之后的所有操作都不会被重排序到volatile之前;
        3、当第一个操作是volatile写操作时,第二个操作是volatile读操作,不能进行重排序。
        这个规则和前面两个规则一起构成了:两个volatile变量操作不能够进行重排序；
    - 可见性

14. 内存屏障/内存栅栏

    内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。
    内存屏障可以被分为以下几种类型：

    - LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。

    - StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。

    - LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。

    - StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。

    在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。

    好处？？

15. happens-before原则
    - 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
    - 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；
    - volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
    - 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
    - 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
    - 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
    - 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
    - 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始

    explain:
    程序次序规则：一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性。

    锁定规则：这个规则比较好理解，无论是在单线程环境还是多线程环境，一个锁处于被锁定状态，那么必须先执行unlock操作后面才能进行lock操作。

    volatile变量规则：这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的。

    传递规则：提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C

    线程启动规则：假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见。

    线程终结规则：假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见。

    上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则：
        - 将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作
        - 将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作
        - 在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作
        - 释放Semaphore许可的操作Happens-Before获得许可操作
        - Future表示的任务的所有操作Happens-Before Future#get()操作
        - 向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作

    happen-before原则是JMM中非常重要的原则，它是判断数据是否存在竞争、线程是否安全的主要依据，保证了多线程环境下的可见性。

15.1. CPU L1,L2,L3缓存 缓存一致性协议 MESI MESIF 以及只写模式，写回模式，写穿模式??

16. Comparable和Comparator的区别
        Comparable是一个类，用于自己和其他相同类型的类比较
        Comparator 是一个接口，用于比较两个对象。
        即一个是用自身和其他比较，一个是比较两个对象16. Comparable和Comparator的区别

17. 线程间通信 wait及notify方法
    
    线程间的相互作用：线程之间需要一些协调通信，来共同完成一件任务,notify wait()方法在Object中可以被继承使用，他们是final方法，无法被重写

    wait():
        wait()方法使得当前线程必须要等待，等到另外一个线程调用notify()或者notifyAll()方法，当前线程必须拥有当前对象的monitor，即lock。
        线程调用wait()方法，释放它对锁的拥有权，然后等待另外的线程来通知它（通知的方式是notify()或者notifyAll()方法），这样它才能重新获得锁的拥有权和恢复执行。
    　　要确保调用wait()方法的时候拥有锁，即，wait()方法的调用必须放在synchronized方法或synchronized块中。
        一个小的比较：
        - wait会释放掉对象的锁， Thread.sleep()不会释放掉对象的锁

    notify():
        notify()方法会唤醒一个等待当前对象的锁的线程,如果多个线程在等待，它们中的一个将会选择被唤醒。这种选择是随意的,被唤醒的线程是不能被执行的，需要等到当前线程放弃这个对象的锁

    wait()和notify()方法要求在调用时线程已经获得了对象的锁，因此对这两个方法的调用需要放在synchronized方法或synchronized块中。

18.  Arrays.sort() and Collection.sort()
    - 该算法是一个经过调优的快速排序，此算法在很多数据集上提供N*log(N)的性能
    - Collection.sort() 一个经过修改的合并排序算,此算法可提供保证的N*log(N)的性能，此实现将指定列表转储到一个数组中，然后再对数组进行排序，在重置数组中相应位置处每个元素的列表上进行迭代

19. java 序列化和反序列化
    Java序列化是指把Java对象转换为字节序列的过程；而Java反序列化是指把字节序列恢复为Java对象的过程
    java.io.ObjectOutputStream：表示对象输出流
    java.io.ObjectInputStream：表示对象输入流
    需要实现了Serializable接口，再看是否定义readObject(ObjectInputStream in)和writeObject(ObjectOutputSteam out)

20. 反射的定义和作用
    是在运行状态中，对于任意的一个类，都能够知道这个类的所有属性和方法，对任意一个对象都能够通过反射机制调用一个类的任意方法，这种动态获取类信息及动态调用类对象方法的功能称为java的反射机制   
    反射的作用：
        - 动态地创建类的实例，将类绑定到现有的对象中，或从现有的对象中获取类型。
        - 应用程序需要在运行时从某个特定的程序集中载入一个特定的类

21. 内存溢出可能原因和解决。
    原因可能是
        - 数据加载过多，如1次从数据库中取出过多数据  
        - 集合类中有对对象的引用，用完后没有清空或者集合对象未置空导致引用存在等，是的JVM无法回收  
        - 死循环，过多重复对象 
        - 第三方软件的bug       
        - 启动参数内存值设定的过小。
    修改JVM启动参数，加内存(-Xms，-Xmx)；错误日志，是否还有其他错误；代码走查

22. redis memorycache, guavacache,caffine的区别
    redis使用单线程模型，数据顺序提交，redis支持主从模式，mencache只支持一致性hash做分布式；redis支持数据落地，rdb定时快照和aof实时记录操作命令的日志备份，memcache不支持；redis数据类型丰富，有string，hash，set，list， sort set，而memcache只支持简单数据类型；memcache使用cas乐观锁做一致性。

23. 分布式唯一ID
确定ID存储用64位，1个64位二进制1是这样的00000000.....1100......0101，切割64位，某段二进制表示成1个约束条件，前41位为毫秒时间，后紧接9位为IP，IP之后为自增的二进制，记录当前面位数相同情况下是第几个id，如现在有10台机器，这个id生成器生成id极限是同台机器1ms内生成2的14次方个ID。

分布式唯一ID = 时间戳 41位， int类型服务器编号  10，序列自增sequence。每个时间戳内只能生成固定数量如（10万）个自增号，达到最大值则同步等待下个时间戳，自增从0开始。将毫秒数放在最高位，保证生成的ID是趋势递增的，每个业务线、每个机房、每个机器生成的ID都是不同的。如39bit毫秒数|4bit业务线|2bit机房|预留|7bit序列号。高位取2016年1月1日1到现在的毫秒数，系统运行10年，至少需要10年x365天x24小时x3600秒x1000毫秒=320x10~9，差不多39bit给毫秒数，每秒单机高峰并发小于100，差不多7bit给每毫秒的自增号，5年内机房小于100台机器，预留2bit给机房，每个机房小于100台机器，预留7bit给每个机房，业务线小于10个，预留4bit给业务线标识。
